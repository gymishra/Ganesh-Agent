{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Description": "AWS Workshop S3 template - Dynamic multi-account support",
  "Parameters": {
    "BucketPrefix": {
      "Type": "String",
      "Default": "dsbucket",
      "Description": "Prefix for S3 bucket name"
    },
    "SourceBucket": {
      "Type": "String",
      "Default": "wrkshp-qbiz-data",
      "Description": "Source S3 bucket containing files to copy"
    },
    "SourcePrefix": {
      "Type": "String",
      "Default": "",
      "Description": "Optional prefix/folder path in source bucket"
    },
    "WorkshopExternalId": {
      "Type": "String",
      "Default": "workshop-sap-genai-2025",
      "Description": "External ID for workshop authentication"
    }
  },
  "Resources": {
    "FileUploadRole": {
      "Type": "AWS::IAM::Role",
      "Properties": {
        "AssumeRolePolicyDocument": {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Allow",
              "Principal": {
                "Service": "lambda.amazonaws.com"
              },
              "Action": "sts:AssumeRole"
            }
          ]
        },
        "ManagedPolicyArns": [
          "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
        ],
        "Policies": [
          {
            "PolicyName": "S3Access",
            "PolicyDocument": {
              "Version": "2012-10-17",
              "Statement": [
                {
                  "Effect": "Allow",
                  "Action": [
                    "sts:AssumeRole"
                  ],
                  "Resource": [
                    "arn:aws:iam::894924264385:role/WorkshopCrossAccountRole"
                  ]
                },
                {
                  "Effect": "Allow",
                  "Action": [
                    "s3:PutObject",
                    "s3:PutObjectAcl",
                    "s3:ListBucket",
                    "s3:GetBucketLocation"
                  ],
                  "Resource": [
                    {"Fn::GetAtt": ["creates3bucket", "Arn"]},
                    {"Fn::Sub": "${creates3bucket.Arn}/*"}
                  ]
                }
              ]
            }
          }
        ]
      }
    },
    "FileUploadFunction": {
      "Type": "AWS::Lambda::Function",
      "Properties": {
        "Runtime": "python3.12",
        "Timeout": 300,
        "Handler": "index.handler",
        "Role": {"Fn::GetAtt": ["FileUploadRole", "Arn"]},
        "Code": {
          "ZipFile": "import boto3\nimport cfnresponse\nimport json\n\ndef handler(event, context):\n    try:\n        print(f'Event: {json.dumps(event, default=str)}')\n        if event['RequestType'] == 'Delete':\n            cfnresponse.send(event, context, cfnresponse.SUCCESS, {})\n            return\n        \n        source_bucket = event['ResourceProperties']['SourceBucket']\n        dest_bucket = event['ResourceProperties']['DestBucket']\n        prefix = event['ResourceProperties'].get('Prefix', '')\n        external_id = event['ResourceProperties']['WorkshopExternalId']\n        \n        print(f'Copying from {source_bucket} to {dest_bucket}')\n        print(f'Using external ID: {external_id}')\n        \n        # Try to assume cross-account role with external ID\n        sts = boto3.client('sts')\n        cross_account_role = 'arn:aws:iam::894924264385:role/WorkshopCrossAccountRole'\n        \n        try:\n            print(f'Attempting to assume role: {cross_account_role}')\n            assumed_role = sts.assume_role(\n                RoleArn=cross_account_role,\n                RoleSessionName=f'WorkshopFileUpload-{context.aws_request_id[:8]}',\n                ExternalId=external_id\n            )\n            \n            # Create S3 client with assumed role credentials\n            source_s3 = boto3.client(\n                's3',\n                aws_access_key_id=assumed_role['Credentials']['AccessKeyId'],\n                aws_secret_access_key=assumed_role['Credentials']['SecretAccessKey'],\n                aws_session_token=assumed_role['Credentials']['SessionToken']\n            )\n            print('Successfully assumed cross-account role')\n            \n        except Exception as assume_error:\n            error_msg = f'Cannot assume cross-account role: {str(assume_error)}'\n            print(error_msg)\n            print('This indicates the workshop cross-account role is not properly configured')\n            print('Please contact the workshop organizer to set up the cross-account role')\n            cfnresponse.send(event, context, cfnresponse.FAILED, {\n                'Error': error_msg,\n                'Solution': 'Workshop organizer needs to create WorkshopCrossAccountRole with universal trust policy'\n            })\n            return\n        \n        # Regular S3 client for destination bucket\n        dest_s3 = boto3.client('s3')\n        \n        # Check if source bucket exists and is accessible\n        try:\n            location = source_s3.get_bucket_location(Bucket=source_bucket)\n            print(f'Source bucket location: {location}')\n            \n            response = source_s3.list_objects_v2(Bucket=source_bucket, MaxKeys=1)\n            print(f'Source bucket accessible, found {response.get(\"KeyCount\", 0)} objects')\n        except Exception as e:\n            error_msg = f'Cannot access source bucket {source_bucket}: {str(e)}'\n            print(error_msg)\n            cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': error_msg})\n            return\n        \n        # List and copy objects\n        paginator = source_s3.get_paginator('list_objects_v2')\n        pages = paginator.paginate(Bucket=source_bucket, Prefix=prefix)\n        \n        files_copied = 0\n        for page in pages:\n            if 'Contents' in page:\n                for obj in page['Contents']:\n                    key = obj['Key']\n                    print(f'Copying {key}')\n                    \n                    try:\n                        # Get object from source bucket\n                        source_obj = source_s3.get_object(Bucket=source_bucket, Key=key)\n                        \n                        # Put object to destination bucket\n                        dest_s3.put_object(\n                            Bucket=dest_bucket,\n                            Key=key,\n                            Body=source_obj['Body'].read(),\n                            ContentType=source_obj.get('ContentType', 'binary/octet-stream')\n                        )\n                        files_copied += 1\n                        print(f'Successfully copied {key}')\n                    except Exception as copy_error:\n                        print(f'Failed to copy {key}: {str(copy_error)}')\n                        # Continue with other files\n        \n        print(f'Successfully copied {files_copied} files')\n        cfnresponse.send(event, context, cfnresponse.SUCCESS, {\n            'FilesUploaded': files_copied,\n            'SourceBucket': source_bucket,\n            'DestinationBucket': dest_bucket\n        })\n        \n    except Exception as e:\n        error_msg = f'Unexpected error: {str(e)}'\n        print(error_msg)\n        cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': error_msg})"
        }
      }
    },
    "creates3bucket": {
      "Type": "AWS::S3::Bucket",
      "Properties": {
        "BucketEncryption": {
          "ServerSideEncryptionConfiguration": [
            {
              "ServerSideEncryptionByDefault": {
                "SSEAlgorithm": "AES256"
              }
            }
          ]
        },
        "BucketName": {"Fn::Sub": "${AWS::AccountId}-${BucketPrefix}-${AWS::StackName}"},
        "OwnershipControls": {
          "Rules": [
            {
              "ObjectOwnership": "BucketOwnerEnforced"
            }
          ]
        },
        "PublicAccessBlockConfiguration": {
          "BlockPublicAcls": true,
          "BlockPublicPolicy": true,
          "IgnorePublicAcls": true,
          "RestrictPublicBuckets": true
        },
        "VersioningConfiguration": {
          "Status": "Enabled"
        }
      }
    },
    "UploadFiles": {
      "Type": "Custom::FileUpload",
      "Properties": {
        "ServiceToken": {"Fn::GetAtt": ["FileUploadFunction", "Arn"]},
        "SourceBucket": {"Ref": "SourceBucket"},
        "DestBucket": {"Ref": "creates3bucket"},
        "Prefix": {"Ref": "SourcePrefix"},
        "WorkshopExternalId": {"Ref": "WorkshopExternalId"}
      },
      "DependsOn": "creates3bucket"
    }
  },
  "Outputs": {
    "S3BucketName": {
      "Description": "Name of the created S3 bucket",
      "Value": {"Ref": "creates3bucket"},
      "Export": {
        "Name": {"Fn::Sub": "${AWS::StackName}-S3BucketName"}
      }
    },
    "FilesUploaded": {
      "Description": "Number of files automatically uploaded",
      "Value": {"Fn::GetAtt": ["UploadFiles", "FilesUploaded"]}
    },
    "WorkshopAccountId": {
      "Description": "AWS Account ID of this workshop participant",
      "Value": {"Ref": "AWS::AccountId"}
    }
  }
}
